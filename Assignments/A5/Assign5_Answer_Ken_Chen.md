# Assignment 5
#### Instructor:  Dr Evans

### Q1:
(a) The experiment I choose is "Experimental survey about the future of voice assistance".

(b) Participants would be paid $0.08 once they finish.

(c) The only qualification requirement is that participants must have a HIT approval rate greater than 98.

(d) The experiment takes about 15 minutes to finish, thus with an hourly rate of $0.32 (which doesn't make that much sense since one is only allowed to take the experiment for once).

(e) This will expire on Nov.15 2018.

(f) The maximum cost would be $0.08*1,000,000 = $80,000 if one million people engaged.

----------------------------------------
### Q2:
The paper accomplished by Costa and Kahn (2013) poses an interesting research question: How would political ideology and environmentalism affect people's response to energy conservation 'nudges', which is reporting energy usage of their own and their peers? **(Costa & Kahn, 2013, p.681)**

To conduct the analysis, several datasets were utilized: The primary data is from "residential billing data from January 2007 to October 2009", which informs the researchers of households' energy consumption behavior, including "kilowatt hours purchased per billing cycle, the length of the billing cycle (measured in days),whether the house uses electric
heat, and whether the household is enrolled in the electric utilityâ€™s program to purchase energy from renewable sources". Another merged dataset is the "individual voter registration and marketing data for March 2009",  and these data help to identify individual political standpoint and preference to environmentalism **(Costa & Kahn, 2013, p.685)**.

In the HER(Home Electricity Report) experiment, they purposely targeted at households from "85 census tracts with a high density of single-family homes"**(Costa & Kahn, 2013, p.683)**. They retained households with a valid account, a persistent electric usage, and living a moderately sized house, and then randomly assign them into treatment group and control group on a contiguous-five "batch block" basis. The process continued until both groups reach a population of 35,000 and the remaining homes were assigned to control. By experiment design, the treatment group have been receiving their monthly or quarterly Home Electricity Reports consecutively while the control will never received one **(Costa & Kahn, 2013, p.683)**.

This paper distinguished itself from the previous studies in way that it controls for further heterogeneity. The previous work by Schultz et al.(2007) divided their sample into two categories: "those with energy consumption above average for the community and those with energy consumption below average for the community." **(Schultz et al., 2007)**, which served their control variable. In Costa & Kahn's work, they controlled for more domains: "household and month, year fixed effects, a cubic in mean daily temperature within the billing cycle, and an interaction of the cubic mean daily temperature with a dummy indicator if the house is an electric house (Temp, Electric)" **(Costa & Kahn, 2013, pp.689-690)**. Besides these, they included some interaction terms between treatment and party registration, green indicators, control characteristics for individual, house and block. In the probit model to predict compliance to treatments, they included whether the household's consumption is above average, usage of electricity in 2006, whether liberal and whether unregistered as controls. **(Costa & Kahn, 2013, pp.689-690)** 

Their principal finding is that compared to conservatives, political liberals are two to four times more responsive to electricity conservation "nudge" in the form of reports on their own usage and their peers'.

### Reference
Costa, Dora L. and Matthew E. Kahn, Energy Conservation Nudges and Envi-
ronmentalist Ideology: Evidence from a Randomized Residential Electricity Field Experiment," *Journal of the European Economic Association*, June 2013, 11 (3), 680-702.

Schultz, P. Wesley, Jessica M. Nolan, Robert B. Cialdini, Noah J. Gold-
steinand, and Vladas Griskevicius, The Constructive, Destructive, and Re-
constructive Power of Social Norms," *Psychological Science*, 2007, 18 (5), 429-434.

-----------------------------------
### Q3
(a) Suppose we want to measure the Average Treatment Effect of receiving text message reminders on vaccination uptake. 
- The merits associated with selecting fewer clinics and spending more of the budget on recruiting experiment participants are: (1) we want to have a larger population size and reduce the variability of the ATE estimand statistically; (2) It is easier to execute the experiments on fewer sites and monitor the process. However, to ensure the experiment validity, we have to make Stable Unit Treatment Value Assumptions, part of it requires 'no hidden treatments' or 'excludibility' **(Salganik, 2018, pp. 203-209)**. Limiting the number of clinics might signal the patients limited locations to uptake the vaccination. For example, if the cooperating clinics are in certain neighborhoods, then what we would estimate is the integrated effects of text message reminders, geographical proximity to the clinics and even other socioeconomic characteristics.
- When there might exist many unobserved determinant factors associated with clinics, we should work with more clinics. By doing so, we are actually adding more variability and trying to eliminate 'hidden treatments'.

(b) The smallest effect size is generally determined by estimate validity and variance. To break them down:
- Experiment design: we have to make sure the our estimate is consistent, which requires our experiment design has a sound theoretical base and complies with the potential outcomes framework. The more 'correct' we are, the smaller the effect size we are able to detect.
- Other factors held equal, what might affect the estimate variance are: (1) number of participants. The more patients there, the more precise our estimate would be. (2) The variance of potential outcomes when treated or untreated, and their covariance. The smaller they are, the more the effect size are detectable. (3) The relative variance of potential outcomes under treatment or non-treatment. Based on their relative value, we can adjust our relative sample sizes in two groups to raise the estimate precision.

### Reference
Salganik, Matthew J., Bit by Bit: Social Research in the Digital Age, Princeton University Press, 2018.
